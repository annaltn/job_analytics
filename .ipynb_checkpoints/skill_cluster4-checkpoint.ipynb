{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "+ Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.feature_extraction.text as text_manip\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from time import time\n",
    "from scipy.sparse import *\n",
    "\n",
    "# my own modules\n",
    "from my_util import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = 'd:/larc_projects/job_analytics/'\n",
    "DATA_DIR = HOME_DIR + 'data/clean/'\n",
    "REPORT_DIR = HOME_DIR + 'reports/skill_cluster/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "There are two goals: i) to remove JDs with too few skills, and ii) to remove skills occurring in too few JDs. Thus, we repeat the following process until the two goals are satisfied.\n",
    "+ Count no. of __unique__ skills in each JD\n",
    "+ Remove JDs with $\\le 1$ skills\n",
    "+ Count no. of JDs containing each skill\n",
    "+ Remove skills occuring in $\\le 1$ JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# posts, skills = helpers.filtering(init_posts, init_skills=skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# job descriptions (JDs)\n",
    "posts = pd.read_csv(DATA_DIR + 'posts.csv')\n",
    "jd_docs = list(posts['clean_text'].apply(str.lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skill_df = pd.read_csv(DATA_DIR + 'skills.csv')\n",
    "skills = skill_df['skill']\n",
    "\n",
    "n_skill, n_jd = len(skills) , posts.shape[0]\n",
    "print('No. of skills: %d' %n_skill)\n",
    "print('No. of JDs: %d' %n_jd) # some garbage JDs with no text already removed\n",
    "print('3 most popular skills')\n",
    "skill_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('3 least popular skills')\n",
    "skill_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# skill_df['n_word'] = skill_df['skill'].apply(my_util.n_word)\n",
    "# skill_df.to_csv(DATA_DIR + 'skills.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Maximum length (no. of words) of skills: %d' \n",
    "      % max(occur_df['n_word']))\n",
    "\n",
    "uni_gram_skills = occur_df.query('n_word == 1')['skill']\n",
    "bi_gram_skills = occur_df.query('n_word == 2')['skill']\n",
    "tri_gram_skills = occur_df.query('n_word == 3')['skill']\n",
    "\n",
    "print('Among them, we have:' )\n",
    "pd.DataFrame([len(uni_gram_skills), len(bi_gram_skills), len(tri_gram_skills)],\n",
    "            index=['n_unigram_skill', 'n_bigram_skill', 'n_trigram_skill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurrence of unigram, bigram and trigram skills in JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_occur = skill_df.query('n_word == 1')['n_jd_with_skill']\n",
    "unigram_quant = my_util.quantile(unigram_occur)\n",
    "\n",
    "bigram_occur = skill_df.query('n_word == 2')['n_jd_with_skill']\n",
    "bigram_quant = my_util.quantile(bigram_occur)\n",
    "\n",
    "trigram_occur = skill_df.query('n_word == 3')['n_jd_with_skill']\n",
    "trigram_quant = my_util.quantile(trigram_occur)\n",
    "\n",
    "occur_quant = pd.concat([unigram_quant, bigram_quant, trigram_quant])\n",
    "occur_quant.index = ['unigram skills', 'bigram skills', 'trigram skills']\n",
    "occur_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occur_quant.to_csv(REPORT_DIR + 'skill_occur.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gram_occur = {1: unigram_occur, 2: bigram_occur, 3: trigram_occur}\n",
    "plt.hist(x=gram_occur[1], bins=np.unique(gram_occur[1]))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.title('1-gram')\n",
    "plt.xlabel('# JDs containing skill')\n",
    "plt.ylabel('# skills')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot1(df=gram_occur, w=10, h=6):\n",
    "    \n",
    "    fig = plt.figure(figsize=(w, h)) \n",
    "    for i in range(3):\n",
    "        n = i+1\n",
    "        plt.subplot(3, 1, n)\n",
    "        plt.subplots_adjust(wspace=.5, hspace=.5)\n",
    "\n",
    "        plt.hist(x=df[n], bins=np.unique(df[n]))\n",
    "        plt.xscale('log')\n",
    "\n",
    "        plt.xlabel('# JDs containing skill')\n",
    "        plt.ylabel('# {}-gram skills'.format(n))\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig1 = plot1(w=7, h=10)\n",
    "# fig1.savefig(REPORT_DIR + 'skill_occur.pdf')\n",
    "# fig1.savefig(REPORT_DIR + 'skill_occur.jpeg')\n",
    "plt.close(fig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Sample job posts')\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=posts['n_uniq_skill'], bins=np.unique(posts['n_uniq_skill']))\n",
    "# plt.title('Skill count')\n",
    "plt.xlabel('# skills in JD')\n",
    "plt.ylabel('# JDs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countOccur_ngram(n=1):\n",
    "    t0 = time()\n",
    "    print('Marking occurrence of {}-gram skills...'.format(n))\n",
    "    vectorizer = text_manip.CountVectorizer(vocabulary=skills, binary=True, ngram_range=(n,n))\n",
    "    doc_ngram_occurrence = vectorizer.fit_transform(jd_docs)\n",
    "    print('Done after %.1fs' %(time() - t0))\n",
    "    n_ngram_by_jd = doc_ngram_occurrence.sum(axis=1).A1\n",
    "    return pd.DataFrame({'job_id': posts['job_id'], 'n_{}gram'.format(n): n_ngram_by_jd})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Consider only n-grams separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_occur = countOccur_ngram(n=1)\n",
    "bigram_occur = countOccur_ngram(n=2)\n",
    "trigram_occur = countOccur_ngram(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occur_df = pd.merge(unigram_occur, bigram_occur, on='job_id')\n",
    "occur_df = pd.merge(occur_df, trigram_occur, on='job_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occur_df['n_skill'] = occur_df['n_1gram'] + occur_df['n_2gram'] + occur_df['n_3gram']\n",
    "occur_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from my_util import *\n",
    "n_skill_by_jd = pd.concat([quantile(occur_df['n_1gram']), quantile(occur_df['n_2gram']), quantile(occur_df['n_3gram'])])\n",
    "n_skill_by_jd.index = ['n_unigram', 'n_bigram', 'n_trigram']\n",
    "n_skill_by_jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_skill_by_jd.to_csv(REPORT_DIR + 'skill_by_jd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot2(w=7, h=10):    \n",
    "    fig = plt.figure(figsize=(w,h))\n",
    "    for i in range(3):\n",
    "        n = i+1\n",
    "        plt.subplot(3, 1, n)\n",
    "        plt.subplots_adjust(hspace=.25)\n",
    "\n",
    "        ngram_occur = occur_df['n_{}gram'.format(n)]\n",
    "        m, bins, patches = plt.hist(x=ngram_occur, bins=np.unique(ngram_occur), align='left')\n",
    "        plt.xlim(0, max(bins)+1)\n",
    "\n",
    "        if (n==3):\n",
    "            plt.xticks(range(11))\n",
    "    #     plt.title('{}-gram'.format(n))\n",
    "        plt.xlabel('# {}-gram skills'.format(n), fontsize='large')\n",
    "        plt.ylabel('# JDs', fontsize='large')\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig2 = plot2()\n",
    "fig2.savefig(REPORT_DIR + 'n_skill_in_jd.pdf')\n",
    "fig2.savefig(REPORT_DIR + 'n_skill_in_jd.jpeg')\n",
    "plt.close(fig2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
