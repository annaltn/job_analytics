{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA and NMF on New Job-Skill Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ja_helpers as ja_helpers; from ja_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = 'd:/larc_projects/job_analytics/'; DATA_DIR = HOME_DIR + 'data/clean/'\n",
    "RES_DIR = HOME_DIR + 'results/skill_cluster/new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skill_df = pd.read_csv(DATA_DIR + 'skill_index.csv')\n",
    "doc_skill = mmread(DATA_DIR + 'doc_skill.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skills from the skill index: 13387\n",
      "# skills in matrix doc-skill: 13387\n",
      "# documents in matrix doc-skill: 137554\n"
     ]
    }
   ],
   "source": [
    "skills = skill_df['skill']\n",
    "print('# skills from the skill index: %d' %len(skills))\n",
    "n_doc = doc_skill.shape[0]; n_skill = doc_skill.shape[1]\n",
    "print ('# skills in matrix doc-skill: %d' %n_skill)\n",
    "print('# documents in matrix doc-skill: %d' %n_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## May not be needed\n",
    "# doc_index = pd.read_csv(DATA_DIR + 'doc_index.csv')\n",
    "# jd_docs = doc_index['doc']; print('# JDs: %d' %len(jd_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA and NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global arguments:\n",
    "   + no. of topics: _k_ in {5, 10, ..., 20}\n",
    "   + no. of top words to be printed out in result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks  = range(15, 35, 5) # ks = [15]\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# docs: 137554, # skills: 13387\n"
     ]
    }
   ],
   "source": [
    "print('# docs: {}, # skills: {}'.format(n_doc, n_skill))\n",
    "in_train, in_test = mkPartition(n_doc, p=80)\n",
    "\n",
    "doc_skill = doc_skill.tocsr()\n",
    "lda_X_train, lda_X_test = doc_skill[in_train, :], doc_skill[in_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init LDA with priors: alpha = 3.3, beta = 0.1\n",
      "Init LDA with priors: alpha = 2.5, beta = 0.1\n",
      "Init LDA with priors: alpha = 2.0, beta = 0.1\n",
      "Init LDA with priors: alpha = 1.7, beta = 0.1\n",
      "Fitting LDA models...\n",
      "No. of topics, Log-likelihood, Running time\n",
      "15, -91558763.1, 94.3s\n",
      "20, -122211250.6, 116.2s\n",
      "25, -153183172.4, 134.0s\n",
      "30, -184478906.9, 156.2s\n"
     ]
    }
   ],
   "source": [
    "beta = 0.1 # or 200/W\n",
    "lda = trainLDA(beta, ks, trainning_set=lda_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LDA_DIR = RES_DIR + 'lda/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ks = [20, 30]\n",
    "for k in ks:\n",
    "    doc_topic_distr = lda[k].transform(doc_skill)\n",
    "    fname = RES_DIR + 'doc_{}topic_distr.mtx'.format(k)\n",
    "    with(open(fname, 'w')) as f:\n",
    "        mmwrite(f, doc_topic_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of LDA on test set by perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best no. of topics for LDA: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of topics</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>4.114925e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>6.788623e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>1.356383e+41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>3.309600e+49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. of topics    Perplexity\n",
       "0             15  4.114925e+24\n",
       "1             20  6.788623e+32\n",
       "2             25  1.356383e+41\n",
       "3             30  3.309600e+49"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp_df = testLDA(lda, ks, test_set=lda_X_test)\n",
    "perp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perp_df.to_csv(LDA_DIR + 'perplexity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Save LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in [25, 30]:\n",
    "#     word_dist = pd.DataFrame(lda[k].components_).apply(normalize, axis=1)\n",
    "#     word_dist.to_csv(LDA_DIR + 'lda_word_dist_{}topics.csv'.format(k), index=False)\n",
    "    \n",
    "    lda_topics = top_words_df(n_top_words=10, model=lda[k], feature_names=skills)\n",
    "    lda_topics.to_csv(LDA_DIR + '{}topics.csv'.format(k), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ks  = range(5, 25, 5)\n",
    "for k in ks:\n",
    "    topic_word_dist = lda[k].components_\n",
    "    fname = LDA_DIR + 'word_dist_{}_topics.mtx'.format(k)\n",
    "    with(open(fname, 'w')) as f:\n",
    "        mmwrite(f, topic_word_dist)\n",
    "#         nrow = topic_word_dist.shape[0]\n",
    "#         for r in range(nrow):\n",
    "#             f.write(topic_word_dist[r, :])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignning skill clusters to job posts\n",
    "\n",
    "The clusters are top-$k$ clusters where we either \n",
    "+ fix $k$ OR \n",
    "+ choose $k$ for each JD such that the cumulative prob of $k$ clusters is larger than a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = pd.read_csv(LDA_DIR + 'cluster.csv')['cluster']\n",
    "n_cluster = len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_index.shape\n",
    "doc_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_index.to_csv(DATA_DIR + 'doc_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic_distr = lda[15].transform(doc_skill)\n",
    "with(open(LDA_DIR + 'doc_topic_distr.mtx', 'w')) as f:\n",
    "    mmwrite(f, doc_topic_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thres = 0.4 # 0.5\n",
    "t0 = time()\n",
    "# doc_index['top_clusters'] = doc_index.apply(getTopTopics_GT, axis=1, doc_topic_distr=doc_topic_distr, thres=0.5)\n",
    "# doc_index['n_top_cluster_40'] = doc_index.apply(getTopTopics_GT, axis=1, doc_topic_distr=doc_topic_distr, thres=thres)\n",
    "doc_index['prob_top_cluster'] = doc_index.apply(getTopTopicProb, axis=1, doc_topic_distr=doc_topic_distr)\n",
    "\n",
    "print('Done after %.1fs' %(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = doc_index.query('n_skill >= 2')\n",
    "res.sort_values('n_skill', ascending=False, inplace=True)\n",
    "print('No. of JDs in result: %d' %res.shape[0])\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sample = 100\n",
    "res.head(n_sample).to_csv(LDA_DIR + 'new/cluster_100top_docs.csv', index=False)\n",
    "res.tail(n_sample).to_csv(LDA_DIR + 'new/cluster_100bottom_docs.csv', index=False)\n",
    "# res.to_csv(LDA_DIR + 'new/cluster_assign2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.rename(columns={'n_top_cluster_40': 'n_top_cluster'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster assignment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see when the cluster assignment to job post is __clear__ or __fuzzy__. The former (latter) means that we the list of top clusters assigned to the post has at most 3 clusters (more than 3 clusters) respectively.\n",
    "\n",
    "+ First, we look at those posts with clear assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_assign = res.query('n_top_cluster <= 3'); fuzzy_assign = res.query('n_top_cluster > 3')\n",
    "print('# posts with clear assignment: %d'  %clear_assign.shape[0])\n",
    "print('Distribution of skills in these posts:')\n",
    "quantile(clear_assign['n_skill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These posts contain lots of skills. Only 25% of them contain no more than 31 skills in each post, so each of the remaining 75% contains at least 31 skills. We can contrast this quartile with the skill distribution in all job posts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Distribution of skills in all posts:')\n",
    "quantile(res['n_skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plotSkillDist(res)\n",
    "plt.savefig(LDA_DIR + 'fig/n_skill_hist.jpg')\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Examples of clear vs. fuzzy assignment can be seen in result file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster assignment statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv(LDA_DIR + 'new/cluster_assign.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between n_top_cluster and n_skill in job posts\n",
    "\n",
    "We can roughly divide job posts into 4 following groups based on the above quartile:\n",
    "+ G1: $ 2 \\le $ n_skill $ \\le 7 $; G2: $ 7 < $ n_skill $ \\le 12 $\n",
    "+ G3: $ 12 < $ n_skill $ \\le 18 $; G4: $ 18 < $ n_skill $ \\le 115 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = res.query('n_skill < 7'); g2 = res.query('n_skill >= 7 & n_skill < 12')\n",
    "g3 = res.query('n_skill >= 12 & n_skill < 18'); g4 = res.query('n_skill >= 18')\n",
    "\n",
    "print('# posts in 4 groups:'); \n",
    "print(','.join([str(g1.shape[0]), str(g2.shape[0]), str(g3.shape[0]), str(g4.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box plot of mixture size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bp = mixtureSizePlot(g1, g2, g3, g4)\n",
    "plt.savefig(LDA_DIR + 'fig/boxplot_mixture_size.pdf'); plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot reveals the following:\n",
    "\n",
    "+ the median mixture size decreases when we have more skills in job post. This is expected as more skills should give clearer assignment. \n",
    "+ when $ 2 \\le $ n_skill $ \\le 7 $ and $ 12 < $ n_skill $ \\le 18 $, the mixture size is resp 7 and 6 most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error bar plot of mixture size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thres = 0.4\n",
    "fig = errorBarPlot(res, thres=thres)\n",
    "plt.savefig(LDA_DIR + 'fig/mixture_size_thres{}.jpg'.format(int(thres*100)))\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probability of top cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = topClusterProbPlot(g1, g2, g3, g4)\n",
    "plt.savefig(LDA_DIR + 'fig/top_cluster_prob.jpg')\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMF_DIR = RES_DIR + 'new/nmf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building TF-IDF matrix\n",
    "\n",
    "Need to proceed like LDA i.e. we need to calculate tfidf for trigram skills, remove them, then calculate tfidf for bigram skills, remove then calculate tfidf for unigram skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO\n",
    "tf_idf_vect = text_manip.TfidfVectorizer(vocabulary=skills, ngram_range=(1, max_n_word))\n",
    "n_instance, n_feat = posts.shape[0], len(skills)\n",
    "t0 =time()\n",
    "print('Building tf_idf for %d JDs using %d features (skills)...' %(n_instance, n_feat))\n",
    "doc_skill_tfidf = tf_idf_vect.fit_transform(posts['clean_text'])\n",
    "print('Done after %.1fs' %(time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnmf = {k: NMF(n_components=k, random_state=0) for k in ks}\n",
    "print( \"Fitting NMF using random initialization...\" )\n",
    "print('No. of topics, Error, Running time')\n",
    "rnmf_error = []\n",
    "\n",
    "for k in ks:\n",
    "    t0 = time()\n",
    "    rnmf[k].fit(X_train)\n",
    "    elapsed = time() - t0\n",
    "    err = rnmf[k].reconstruction_err_\n",
    "    print('%d, %0.1f, %0.1fs' %(k, err, elapsed))\n",
    "    rnmf_error.append(err)\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Save models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_features = tf_idf_vect.get_feature_names()\n",
    "pd.DataFrame(nmf_features).to_csv(RES_DIR + 'nmf_features.csv', index=False)\n",
    "\n",
    "for k in ks:\n",
    "    top_words = top_words_df(n_top_words, model=rnmf[k],feature_names=nmf_features)\n",
    "    top_words.to_csv(RES_DIR + 'nmf_{}_topics.csv'.format(k), index=False)\n",
    "#   each word dist is a component in NMF\n",
    "    word_dist = pd.DataFrame(rnmf[k].components_).apply(normalize, axis=1)\n",
    "    word_dist.to_csv(RES_DIR + 'nmf_word_dist_{}topics.csv'.format(k), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Calculating test errors of random NMF ...')\n",
    "rnmf_test_error = cal_test_err(mf_models=rnmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_k = ks[np.argmin(rnmf_test_error)]\n",
    "print('The best no. of topics is %d' %best_k)\n",
    "rnmf_best = rnmf[best_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_fig = plotMetrics(train_metric=rnmf_error, test_metric=rnmf_test_error, model_name='NMF')\n",
    "nmf_fig.savefig(RES_DIR + 'nmf.pdf')\n",
    "plt.close(nmf_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all model metrics on training & test datasets into 2 data frames\n",
    "model_list = ['LDA', 'randomNMF']\n",
    "\n",
    "train_metric = pd.DataFrame({'No. of topics': ks, 'LDA': np.divide(lda_scores, 10**6), 'randomNMF': rnmf_error})\n",
    "test_metric = pd.DataFrame({'No. of topics': ks, 'LDA': perp, 'randomNMF': rnmf_test_error, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, model in enumerate(model_list):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.subplots_adjust(wspace=.5, hspace=.5)  \n",
    "    #     train metric\n",
    "    plt.title(model)\n",
    "    plt.plot(ks, train_metric[model], '--')\n",
    "    plt.xlabel('No. of topics')\n",
    "    if model == 'LDA':\n",
    "        plt.ylabel(r'Log likelihood ($\\times 10^6$)')\n",
    "    else:\n",
    "        plt.ylabel(r'$\\| X_{train} - W_{train} H \\|_2$')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(ks)\n",
    "    \n",
    "    #     test metric\n",
    "    plt.subplot(2, 2, i+3)\n",
    "    plt.title(model)\n",
    "    plt.plot(ks, test_metric[model], 'r')\n",
    "    plt.xlabel('No. of topics')\n",
    "    if model == 'LDA':\n",
    "        plt.ylabel(r'Perplexity')\n",
    "    else:\n",
    "        plt.ylabel(r'$\\| X_{test} - W_{test} H \\|_2$')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(ks)\n",
    "        \n",
    "# end\n",
    "plt.show()\n",
    "fig.savefig(RES_DIR + 'lda_vs_nmf.pdf')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
